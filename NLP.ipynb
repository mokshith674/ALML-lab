{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNX2Uh0EtIfWrlfYv7TLHwX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokshith674/ALML-lab/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOnnPEYwDbn5",
        "outputId": "fc13d10b-dd93-4b5b-df18-66dec14a2c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing 1refers to the branch of computer @science and\n",
            "more specifically, the branch of 3\" artificial intelligence\" or AI, concer\n",
            "ned with giving computers the ability to understand text and spoken words\n",
            "in much the same way human beings can. NLP combines computational linguist\n",
            "ics with statistical, [machine learning, and deep learning models. Togethe\n",
            "r, these technologies enable computers to process human language in the fo\n",
            "rm of text or voice data and to understand its full meaning, complete with\n",
            "the speaker or writer's intent and sentiment.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "file=open('/content/nlp.txt',\"r\")\n",
        "text=file.read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30N6AD_5EaUR",
        "outputId": "67f2e877-1f0d-49fa-ea3a-4c76002213e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization"
      ],
      "metadata": {
        "id": "Z3gFT9PiEHxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=sent_tokenize(text)"
      ],
      "metadata": {
        "id": "F6HsIjkhDn5r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number opf sentences:\",len(sentences))\n",
        "for i in range(len(sentences)):\n",
        " print(\"\\n sentences\",i+1,\":\\n\",sentences[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibbbh7QzEQN1",
        "outputId": "5087780a-cb76-4587-a4d0-3e9c092c2ce4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number opf sentences: 3\n",
            "\n",
            " sentences 1 :\n",
            " Natural language processing 1refers to the branch of computer @science and\n",
            "more specifically, the branch of 3\" artificial intelligence\" or AI, concer\n",
            "ned with giving computers the ability to understand text and spoken words\n",
            "in much the same way human beings can.\n",
            "\n",
            " sentences 2 :\n",
            " NLP combines computational linguist\n",
            "ics with statistical, [machine learning, and deep learning models.\n",
            "\n",
            " sentences 3 :\n",
            " Togethe\n",
            "r, these technologies enable computers to process human language in the fo\n",
            "rm of text or voice data and to understand its full meaning, complete with\n",
            "the speaker or writer's intent and sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word **tokenization**"
      ],
      "metadata": {
        "id": "IhcPu3SvEyuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "words=word_tokenize(text)\n",
        "print(\"total number of words:\",len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP3UqymVEow2",
        "outputId": "67a01380-22bc-4f89-8c74-6d77a14dc534"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of words: 103\n",
            "['Natural', 'language', 'processing', '1refers', 'to', 'the', 'branch', 'of', 'computer', '@', 'science', 'and', 'more', 'specifically', ',', 'the', 'branch', 'of', '3', \"''\", 'artificial', 'intelligence', \"''\", 'or', 'AI', ',', 'concer', 'ned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'words', 'in', 'much', 'the', 'same', 'way', 'human', 'beings', 'can', '.', 'NLP', 'combines', 'computational', 'linguist', 'ics', 'with', 'statistical', ',', '[', 'machine', 'learning', ',', 'and', 'deep', 'learning', 'models', '.', 'Togethe', 'r', ',', 'these', 'technologies', 'enable', 'computers', 'to', 'process', 'human', 'language', 'in', 'the', 'fo', 'rm', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', 'understand', 'its', 'full', 'meaning', ',', 'complete', 'with', 'the', 'speaker', 'or', 'writer', \"'s\", 'intent', 'and', 'sentiment', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing stop words"
      ],
      "metadata": {
        "id": "M0VLnFuEFN_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DiLQG91FkV4",
        "outputId": "899e42e2-73a1-4f20-c48c-656531f04c14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "words=word_tokenize(text)\n",
        "stopwords=nltk.corpus.stopwords.words('english')\n",
        "words_sw_removed=[]\n",
        "for words in words:\n",
        "  if words in stopwords:\n",
        "    pass\n",
        "  else:\n",
        "    words_sw_removed.append(words)\n",
        "print(words_sw_removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHkRbjwsE_m1",
        "outputId": "2ee60a48-5b07-433a-ad48-30fe34c6a331"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'language', 'processingrefers', 'branch', 'computer', 'science', 'specifically', 'branch', 'ofartificial', 'intelligence', 'AI', 'concer', 'ned', 'giving', 'computers', 'ability', 'understand', 'text', 'spoken', 'words', 'much', 'way', 'human', 'beings', 'NLP', 'combines', 'computational', 'linguist', 'ics', 'statistical', 'machine', 'learning', 'deep', 'learning', 'models', 'Togethe', 'r', 'technologies', 'enable', 'computers', 'process', 'human', 'language', 'fo', 'rm', 'text', 'voice', 'data', 'understand', 'full', 'meaning', 'complete', 'speaker', 'writer', 'intent', 'sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing punctuions by a single space"
      ],
      "metadata": {
        "id": "w5BJZsDJF_L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text=re.sub('[^A-Za-z0-9]+',' ',text)\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWl9ugUuFaLH",
        "outputId": "e44ee3dc-1c81-40e1-a043-c5f6abfa494e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing 1refers to the branch of computer science and more specifically the branch of 3 artificial intelligence or AI concer ned with giving computers the ability to understand text and spoken words in much the same way human beings can NLP combines computational linguist ics with statistical machine learning and deep learning models Togethe r these technologies enable computers to process human language in the fo rm of text or voice data and to understand its full meaning complete with the speaker or writer s intent and sentiment \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after performing puntuations"
      ],
      "metadata": {
        "id": "ckhX3s-GGV1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "bigram=ngrams(text.split(),2)\n",
        "for item in bigram:\n",
        " print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW6xEx0WGGf2",
        "outputId": "245fb8ad-ce24-4114-b582-fa7302a22cdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Natural', 'language')\n",
            "('language', 'processing')\n",
            "('processing', '1refers')\n",
            "('1refers', 'to')\n",
            "('to', 'the')\n",
            "('the', 'branch')\n",
            "('branch', 'of')\n",
            "('of', 'computer')\n",
            "('computer', 'science')\n",
            "('science', 'and')\n",
            "('and', 'more')\n",
            "('more', 'specifically')\n",
            "('specifically', 'the')\n",
            "('the', 'branch')\n",
            "('branch', 'of')\n",
            "('of', '3')\n",
            "('3', 'artificial')\n",
            "('artificial', 'intelligence')\n",
            "('intelligence', 'or')\n",
            "('or', 'AI')\n",
            "('AI', 'concer')\n",
            "('concer', 'ned')\n",
            "('ned', 'with')\n",
            "('with', 'giving')\n",
            "('giving', 'computers')\n",
            "('computers', 'the')\n",
            "('the', 'ability')\n",
            "('ability', 'to')\n",
            "('to', 'understand')\n",
            "('understand', 'text')\n",
            "('text', 'and')\n",
            "('and', 'spoken')\n",
            "('spoken', 'words')\n",
            "('words', 'in')\n",
            "('in', 'much')\n",
            "('much', 'the')\n",
            "('the', 'same')\n",
            "('same', 'way')\n",
            "('way', 'human')\n",
            "('human', 'beings')\n",
            "('beings', 'can')\n",
            "('can', 'NLP')\n",
            "('NLP', 'combines')\n",
            "('combines', 'computational')\n",
            "('computational', 'linguist')\n",
            "('linguist', 'ics')\n",
            "('ics', 'with')\n",
            "('with', 'statistical')\n",
            "('statistical', 'machine')\n",
            "('machine', 'learning')\n",
            "('learning', 'and')\n",
            "('and', 'deep')\n",
            "('deep', 'learning')\n",
            "('learning', 'models')\n",
            "('models', 'Togethe')\n",
            "('Togethe', 'r')\n",
            "('r', 'these')\n",
            "('these', 'technologies')\n",
            "('technologies', 'enable')\n",
            "('enable', 'computers')\n",
            "('computers', 'to')\n",
            "('to', 'process')\n",
            "('process', 'human')\n",
            "('human', 'language')\n",
            "('language', 'in')\n",
            "('in', 'the')\n",
            "('the', 'fo')\n",
            "('fo', 'rm')\n",
            "('rm', 'of')\n",
            "('of', 'text')\n",
            "('text', 'or')\n",
            "('or', 'voice')\n",
            "('voice', 'data')\n",
            "('data', 'and')\n",
            "('and', 'to')\n",
            "('to', 'understand')\n",
            "('understand', 'its')\n",
            "('its', 'full')\n",
            "('full', 'meaning')\n",
            "('meaning', 'complete')\n",
            "('complete', 'with')\n",
            "('with', 'the')\n",
            "('the', 'speaker')\n",
            "('speaker', 'or')\n",
            "('or', 'writer')\n",
            "('writer', 's')\n",
            "('s', 'intent')\n",
            "('intent', 'and')\n",
            "('and', 'sentiment')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "bigram=ngrams(text.split(),3)\n",
        "for item in bigram:\n",
        " print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjS0Xz3xKyKT",
        "outputId": "23b9ca16-a789-4a90-9507-1caf999198b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Natural', 'language', 'processing')\n",
            "('language', 'processing', '1refers')\n",
            "('processing', '1refers', 'to')\n",
            "('1refers', 'to', 'the')\n",
            "('to', 'the', 'branch')\n",
            "('the', 'branch', 'of')\n",
            "('branch', 'of', 'computer')\n",
            "('of', 'computer', 'science')\n",
            "('computer', 'science', 'and')\n",
            "('science', 'and', 'more')\n",
            "('and', 'more', 'specifically')\n",
            "('more', 'specifically', 'the')\n",
            "('specifically', 'the', 'branch')\n",
            "('the', 'branch', 'of')\n",
            "('branch', 'of', '3')\n",
            "('of', '3', 'artificial')\n",
            "('3', 'artificial', 'intelligence')\n",
            "('artificial', 'intelligence', 'or')\n",
            "('intelligence', 'or', 'AI')\n",
            "('or', 'AI', 'concer')\n",
            "('AI', 'concer', 'ned')\n",
            "('concer', 'ned', 'with')\n",
            "('ned', 'with', 'giving')\n",
            "('with', 'giving', 'computers')\n",
            "('giving', 'computers', 'the')\n",
            "('computers', 'the', 'ability')\n",
            "('the', 'ability', 'to')\n",
            "('ability', 'to', 'understand')\n",
            "('to', 'understand', 'text')\n",
            "('understand', 'text', 'and')\n",
            "('text', 'and', 'spoken')\n",
            "('and', 'spoken', 'words')\n",
            "('spoken', 'words', 'in')\n",
            "('words', 'in', 'much')\n",
            "('in', 'much', 'the')\n",
            "('much', 'the', 'same')\n",
            "('the', 'same', 'way')\n",
            "('same', 'way', 'human')\n",
            "('way', 'human', 'beings')\n",
            "('human', 'beings', 'can')\n",
            "('beings', 'can', 'NLP')\n",
            "('can', 'NLP', 'combines')\n",
            "('NLP', 'combines', 'computational')\n",
            "('combines', 'computational', 'linguist')\n",
            "('computational', 'linguist', 'ics')\n",
            "('linguist', 'ics', 'with')\n",
            "('ics', 'with', 'statistical')\n",
            "('with', 'statistical', 'machine')\n",
            "('statistical', 'machine', 'learning')\n",
            "('machine', 'learning', 'and')\n",
            "('learning', 'and', 'deep')\n",
            "('and', 'deep', 'learning')\n",
            "('deep', 'learning', 'models')\n",
            "('learning', 'models', 'Togethe')\n",
            "('models', 'Togethe', 'r')\n",
            "('Togethe', 'r', 'these')\n",
            "('r', 'these', 'technologies')\n",
            "('these', 'technologies', 'enable')\n",
            "('technologies', 'enable', 'computers')\n",
            "('enable', 'computers', 'to')\n",
            "('computers', 'to', 'process')\n",
            "('to', 'process', 'human')\n",
            "('process', 'human', 'language')\n",
            "('human', 'language', 'in')\n",
            "('language', 'in', 'the')\n",
            "('in', 'the', 'fo')\n",
            "('the', 'fo', 'rm')\n",
            "('fo', 'rm', 'of')\n",
            "('rm', 'of', 'text')\n",
            "('of', 'text', 'or')\n",
            "('text', 'or', 'voice')\n",
            "('or', 'voice', 'data')\n",
            "('voice', 'data', 'and')\n",
            "('data', 'and', 'to')\n",
            "('and', 'to', 'understand')\n",
            "('to', 'understand', 'its')\n",
            "('understand', 'its', 'full')\n",
            "('its', 'full', 'meaning')\n",
            "('full', 'meaning', 'complete')\n",
            "('meaning', 'complete', 'with')\n",
            "('complete', 'with', 'the')\n",
            "('with', 'the', 'speaker')\n",
            "('the', 'speaker', 'or')\n",
            "('speaker', 'or', 'writer')\n",
            "('or', 'writer', 's')\n",
            "('writer', 's', 'intent')\n",
            "('s', 'intent', 'and')\n",
            "('intent', 'and', 'sentiment')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ev0HvURvK7JK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}